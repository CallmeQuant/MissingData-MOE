---
title: "SelvarClustMV"
author: "Ho Huu Binh"
date: "`r Sys.Date()`"
toc: true
format:
  html: 
    toc: true
    toc_float: true
    code: true
    code-fold: true
    code-tools: true
  pdf: 
    fontsize: "12"
    toc: true
    number-sections: true
    number-depth: 3
---
Progress:
-7-2-2025:
 + Incorporate MNARz into the framework is not straightforward
   - Full integration => rewrite from the start
   
 + Current approach: Correction step 
   - Partly introduce the MNARz in the final step 
   - Update missing values and resp based on mechanism parameter (alpha)
   - Only use relevant set S for updating => only missing values on these variables will be adjusted 
   
 + Results: Not good 
 

 
 
 
  

```{r}
create_package_tarball <- function(path) {
  Rcpp::compileAttributes(path)

  pkg_name <- basename(path)

  parent_dir <- dirname(path)

  devtools::build(path, path = parent_dir, binary = FALSE)
}
tar_filename <- "D:/RProject/SelvarMix_1.2.1.tar.gz"
if (!file.exists(tar_filename)) {
  create_package_tarball("D:/Rproject/SelvarMix_extend")
}
install.packages("D:/RProject/SelvarMix_1.2.1.tar.gz", repos = NULL, type="source")
```

## Loading libraries
```{r, warning=F, message=F}
rm(list=ls())
library(here)
library(Gmisc)
library(glasso)

library(mvtnorm)
library(Matrix)
library(stats)
library(BMA)
library(mlogitBMA)
library(mlogit)
library(foreach)
library(parallel)
library(doParallel)
library(iterators)
library(reshape2)
library(ggplot2)
library(tidyverse)
library(matrixStats)  # For efficient matrix operations
library(aricode) # For efficient similarity metrics between two classification
source("amputation.R")

# MixAll and SelvarMix
library(SelvarMix)
library(MixAll)

# Benchmarks 
library(VarSelLCM)
library(RMixtComp)
library(Rmixmod)
library(clustvarsel)
library(mclust)
library(MASS)
source("EM_Gaussian_withoutNA.R")
source("EM_Gaussian.R")
source("Functions_misspecification.R")
```


## Helper functions
```{r}
compute_nrmse <- function(original_data, 
                          missing_data, 
                          imputed_data, 
                          normalization = "missing") {
  missing_indices <- is.na(missing_data)
  
  original_missing_values <- original_data[missing_indices]
  imputed_missing_values <- imputed_data[missing_indices]
  
  rmse <- sqrt(mean((original_missing_values - imputed_missing_values)^2))
  
  # Normalization factor
  if (normalization == "sd") {
    # Normalize by the standard deviation of the entire original data
    norm_factor <- sd(as.numeric(unlist(original_data)), na.rm = TRUE)
  } else if (normalization == "missing") {
    # Normalize by the square root of the mean squared actual values at missing positions
    norm_factor <- sqrt(mean(original_missing_values^2))
  } else {
    stop("Invalid normalization method. Use 'sd' or 'missing'.")
  }
  
  # Compute NRMSE
  nrmse <- rmse / norm_factor
  
  return(nrmse)
}

# Function to compute Weighted NRMSE (W-NRMSE)
compute_weighted_nrmse <- function(original_data, 
                                   missing_data, 
                                   imputed_data, 
                                   true_labels, 
                                   normalization = "missing") {
  true_labels <- as.factor(true_labels)
  clusters <- levels(true_labels)
  num_clusters <- length(clusters)
  
  # Initialize variables
  total_nrmse <- 0
  total_weight <- 0
  
  for (cluster in clusters) {
    # Indices for the current cluster
    cluster_indices <- which(true_labels == cluster)
    
    # Indices of missing data within the current cluster
    missing_indices <- which(is.na(missing_data[cluster_indices, ]), arr.ind = TRUE)
    if (nrow(missing_indices) == 0) next  # Skip if no missing data in this cluster
    
    # Extract original and imputed values for missing entries in this cluster
    # original_missing_values <- original_data[cluster_indices, ][missing_indices]
    # imputed_missing_values <- imputed_data[cluster_indices, ][missing_indices]
    original_missing_values <- original_data[cluster_indices, 
                                             ][cbind(missing_indices[,1],
                                                     missing_indices[,2])]
    imputed_missing_values <- imputed_data[cluster_indices, 
                                       ][cbind(missing_indices[,1], 
                                               missing_indices[,2])]

    
    # Compute RMSE for the current cluster
    rmse <- sqrt(mean((original_missing_values - imputed_missing_values)^2))
    
    # Normalization factor
    if (normalization == "sd") {
      norm_factor <- sd(as.numeric(original_data), na.rm = TRUE)
    } else if (normalization == "missing") {
      norm_factor <- sqrt(mean(original_missing_values^2))
    } else {
      stop("Invalid normalization method. Use 'sd' or 'missing'.")
    }
    
    # Compute NRMSE for the current cluster
    nrmse <- rmse / norm_factor
    
    # Weight by the proportion of missing data in this cluster
    weight <- length(original_missing_values)
    
    total_nrmse <- total_nrmse + (nrmse * weight)
    total_weight <- total_weight + weight

  }
  
  # Compute weighted average NRMSE
  weighted_nrmse <- total_nrmse / total_weight
  
  return(weighted_nrmse)
}

# Function to compute Clustering-Integrated Imputation Error (CIIE)
compute_ciie <- function(original_data, 
                         missing_data, 
                         imputed_data, 
                         true_labels,
                         predicted_labels, 
                         normalization = "missing", 
                         similarity = "ARI",
                         alpha = 0.4,  # Weight for imputation accuracy
                         beta = 0.6   # Weight for clustering quality
                         ) {
  if ((alpha + beta) != 1) {
    stop("Weights alpha and beta must sum to 1.")
  }
  
  nrmse <- compute_nrmse(original_data, missing_data, imputed_data, normalization)
  
  # invert so that lower error has higher score
  nrmse_score <- 1 - nrmse  
  nrmse_score <- ifelse(nrmse_score < 0, 0, nrmse_score)
  
  # Compute clustering similarity metrics
  similarity_metrics <- clustComp(true_labels, predicted_labels)
  
  # Extract desired similarity metrics
  ari <- similarity_metrics$ARI
  ami <- similarity_metrics$AMI
  nvi <- similarity_metrics$NVI
  nid <- similarity_metrics$NID
  nmi <- similarity_metrics$NMI
  
  # Invert NVI and NID to convert distance metrics to similarity metrics
  nvi_sim <- 1 - nvi
  nid_sim <- 1 - nid
  
  # Ensure all similarity metrics are within [0,1]
  similarity_metrics_processed <- c(
    ARI = max(min(ari, 1), 0),
    AMI = max(min(ami, 1), 0),
    NMI = max(min(nmi, 1), 0),
    NVI = max(min(nvi_sim, 1), 0),
    NID = max(min(nid_sim, 1), 0)
  )
  
  # Compute the average similarity score
  if (similarity == "all"){
  similarity_score <- mean(similarity_metrics_processed)}
  else {
    similarity_score <- similarity_metrics_processed[[similarity]]
  }
  
  # Compute CIIE as a weighted sum of NRMSE score and similarity score
  ciie <- (alpha * nrmse_score) + (beta * similarity_score)
  
  return(ciie)
}


# Strategy settings for MixAll clustering
quick_precise_strategy <- clusterStrategy(
  nbTry = 10,
  nbInit = 5,
  initMethod = "class",
  initAlgo = "SEM",
  nbInitIteration = 5,
  initEpsilon = 1e-4,
  nbShortRun = 5,
  shortRunAlgo = "EM",
  nbShortIteration = 120,
  shortEpsilon = 1e-6,
  longRunAlgo = "EM",
  nbLongIteration = 150,
  longEpsilon = 1e-7
)

# rep_mixmod_strategy <- clusterStrategy(
#   nbTry = 1, #1
#   nbInit = 100, #50
#   initMethod = "random",
#   initAlgo = "EM",
#   nbInitIteration = 20, #5
#   initEpsilon = 0.01,
#   nbShortRun = 5,
#   shortRunAlgo = "EM",
#   nbShortIteration = 100,
#   shortEpsilon = 1e-4,
#   longRunAlgo = "EM",
#   nbLongIteration =200,
#   longEpsilon = 1e-7
# )

rep_mixmod_strategy <- clusterStrategy(
  nbTry = 1,
  nbInit = 100,
  initMethod = "class",
  initAlgo = "SEM",
  nbInitIteration = 10,
  initEpsilon = 1e-4,
  nbShortRun = 10,
  shortRunAlgo = "EM",
  nbShortIteration = 100,
  shortEpsilon = 1e-7,
  longRunAlgo = "EM",
  nbLongIteration = 200,
  longEpsilon = 1e-8
  )

rep_mixmod_strategy_long <- clusterStrategy(
  nbTry = 2, #1
  nbInit = 100, #50
  initMethod = "random",
  initAlgo = "EM",
  nbInitIteration = 20, #5
  initEpsilon = 0.001,
  nbShortRun = 5,
  shortRunAlgo = "EM",
  nbShortIteration = 100,
  shortEpsilon = 1e-07,
  longRunAlgo = "EM",
  nbLongIteration =200,
  longEpsilon = 0.001
)


rotation_matrix_2d <- function(angle) {
   matrix(c(cos(angle), -sin(angle),
            sin(angle), cos(angle)), nrow = 2, byrow = TRUE)}


rotation_matrix_3d <- function(axis, angle) {
  if (axis == "z") {
    matrix(c(cos(angle), -sin(angle), 0,
             sin(angle), cos(angle), 0,
             0, 0, 1), nrow = 3)
  } else if (axis == "x") {
    matrix(c(1, 0, 0,
             0, cos(angle), -sin(angle),
             0, sin(angle), cos(angle)), nrow = 3)
  }
}

mytheme = list(
    theme_classic()+
    theme(panel.background = element_blank(),
          strip.background = element_rect(colour=NA, fill=NA),
          panel.border = element_rect(fill = NA, color = "black"),
          legend.title = element_blank(),legend.position="bottom", 
          strip.text = element_text(face="bold", size=9),
          axis.text=element_text(face="bold"),
          axis.title = element_text(face="bold"),
          plot.title = element_text(face = "bold", hjust = 0.5,size=13)))
```


## Simulated data
### Maugis 2019
```{r}
set.seed(123)

# Number of data points
n <- 2000

# Cluster means for the first two variables (relevant variables)
mu_list <- list(
  c(0, 0),
  c(4, 0),
  c(0, 2),
  c(4, 2)
)

# Generate cluster assignments (equiprobable)
cluster_assignments <- sample(1:4, size = n, replace = TRUE)

# Generate y1_2 based on cluster assignments, using a sharper cluster structure for clarity
# We use a smaller diagonal covariance for more distinct clustering
Sigma_cluster <- diag(c(0.5, 0.5))

y1_2 <- matrix(0, nrow = n, ncol = 2)
for (k in 1:4) {
  idx <- which(cluster_assignments == k)
  nk <- length(idx)
  if (nk > 0) {
    y1_2[idx, ] <- mvrnorm(nk, mu = mu_list[[k]], Sigma = Sigma_cluster)
  }
}

# tilde_alpha 
tilde_alpha <- c(0, 0, seq(0.4, 4, by = 0.4))

# Initialize lists to store datasets and results
data_list <- list()

# Define scenario-specific parameters
for (scenario in 1:8) {
  if (scenario == 1) {
    # Scenario 1
    tilde_beta <- matrix(0, nrow = 2, ncol = 12)
    tilde_Omega_diag <- rep(1, 12)

  } else if (scenario == 2) {
    # Scenario 2
    tilde_beta <- cbind(matrix(c(3, 0), nrow = 2), matrix(0, nrow = 2, ncol = 11))
    tilde_Omega_diag <- c(0.5, rep(1, 11))

  } else if (scenario == 3) {
    # Scenario 3
    tilde_beta <- cbind(matrix(c(0.5, 1), nrow = 2), matrix(0, nrow = 2, ncol = 11))
    tilde_Omega_diag <- rep(1, 12)

  } else if (scenario == 4) {
    # Scenario 4
    beta_1 <- matrix(c(0.5, 1, 2, 0), nrow = 2, ncol = 2)
    tilde_beta <- cbind(beta_1, matrix(0, nrow = 2, ncol = 10))
    tilde_Omega_diag <- rep(1, 12)

  } else if (scenario == 5) {
    # Scenario 5
    beta_1 <- matrix(c(0.5, 1, 2, 0), nrow = 2, ncol = 2)
    beta_2 <- matrix(c(0, 3, -1, 2, 2, -4), nrow = 2, ncol = 3)
    tilde_beta <- cbind(beta_1, beta_2, matrix(0, nrow = 2, ncol = 7))
    tilde_Omega_diag <- c(rep(1, 3), rep(0.5, 5), rep(1, 4))

  } else if (scenario == 6) {
    # Scenario 6
    beta_1 <- matrix(c(0.5, 1, 2, 0), nrow = 2)
    beta_2 <- matrix(c(0, 3, -1, 2, 2, -4), nrow = 2, ncol = 3)
    beta_3 <- matrix(c(0.5, 0, 4, 0.5, 3, 0, 2, 1), nrow = 2, ncol = 4)
    tilde_beta <- cbind(beta_1, beta_2, beta_3, matrix(0, nrow = 2, ncol = 3))
    # Diagonal approximation of Omega for scenario 6
    tilde_Omega_diag <- c(rep(1, 3), rep(0.5, 2), rep(1, 7))

  } else if (scenario == 7) {
    # Scenario 7
    beta_1 <- matrix(c(0.5, 1, 2, 0), nrow = 2)
    beta_2 <- matrix(c(0, 3, -1, 2, 2, -4), nrow = 2, ncol = 3)
    beta_3 <- matrix(c(0.5, 0, 4, 0.5, 3, 0, 2, 1), nrow = 2, ncol = 4)
    additional_betas <- matrix(c(-1, -2, 0, 0.5, 1, 1), nrow = 2, ncol = 3)
    tilde_beta <- cbind(beta_1, beta_2, beta_3, additional_betas)
    tilde_Omega_diag <- c(rep(1, 3), rep(0.5, 2), rep(1, 7))

  } else if (scenario == 8) {
    # Scenario 8
    intercept_8 <- c(0, 0, seq(0.4, by = 0.4, length.out = 7))
    b_8 <- matrix(c(
      0.5,  1,
      2,    0,
      0,    3,
      -1,   2,
      2,   -4,
      0.5,  0,
      4,    0.5,
      3,    0,
      2,    1
    ), nrow = 2, byrow = FALSE)
    Omega_8_diag <- c(rep(1,3), rep(0.5,2), 2.5, 1.5, 3.0, 5.0)
    epsilon_8 <- matrix(rnorm(n * 9), nrow = n, ncol = 9) %*% diag(sqrt(Omega_8_diag))
    y3_11 <- matrix(rep(intercept_8, each = n), n, byrow = FALSE) + (y1_2 %*% b_8) + epsilon_8

    # Add 3 noise variables 12:14
    y12_14 <- matrix(rnorm(n * 3), n, 3)

    # Combine all variables
    data <- cbind(y1_2, y3_11, y12_14)

    # Store and run SelvarClustLasso
    data_list[[scenario]] <- data
    # Move on to the next scenario
    next
  }

  # For scenarios 1 to 7:
  # Generate epsilon with the chosen diagonal covariance
  epsilon <- matrix(rnorm(n * 12), nrow = n, ncol = 12)
  epsilon <- epsilon %*% diag(sqrt(tilde_Omega_diag))

  # Compute y_i^{[3:14]}
  y3_14 <- matrix(rep(tilde_alpha, each = n), nrow = n, byrow = FALSE) + y1_2 %*% tilde_beta + epsilon

  # Combine all variables for scenarios 1-7
  data <- cbind(y1_2, y3_14)
  colnames(data) <- paste0("V", 1:14)
  # Store the dataset
  data_list[[scenario]] <- data
}
names(data_list) <- paste0("Scenario_", 1:8)

```

#### Run exp normal
```{r}
data_missing <- produce_NA(data_list[[8]], mechanism = "MNAR", 
                           perc.missing = 0.2)$data.incomp

result <- SelvarClustLasso(
  x = data_missing, 
  nbcluster = 2:4,
  rmodel = c("LB", "LI"), 
  hsize = 2,
  nbcores = detectCores(logical = TRUE),
  impute_missing = TRUE,
  scale_data = TRUE
)

data_imputed <- missRanger(data_missing)
result2 <-clustvarsel(data_imputed, G=2:4, search="greedy",
                          direction = "backward", emModels1 = "V", 
                          emModels2 = "VVI", allow.EEE = FALSE, 
                          forcetwo = FALSE, parallel = TRUE)


predicted_labels1 <- result$partition
predicted_labels2 <- result2$model$classification
imputed_data1 <- result$imputedData
data_imputed <- as.matrix(data_imputed)

similarity_metrics1 <- clustComp(cluster_assignments, predicted_labels1)
similarity_metrics2 <- clustComp(cluster_assignments, predicted_labels2)

# Compute Metrics for SelvarClustLasso
nrmse1 <- compute_nrmse(original_data = data_list[[8]], 
                        missing_data = data_missing, 
                        imputed_data = imputed_data1, 
                        normalization = "missing")

wnrmse1 <- compute_weighted_nrmse(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = cluster_assignments,
                       normalization = "missing")

ciie1 <- compute_ciie(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = cluster_assignments, 
                       predicted_labels = predicted_labels1, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

# Compute Metrics for clustvarsel
nrmse2 <- compute_nrmse(original_data = data_list[[8]], 
                        missing_data = data_missing, 
                        imputed_data = data_imputed, 
                        normalization = "missing")

wnrmse2 <- compute_weighted_nrmse(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = cluster_assignments, 
                       normalization = "missing")

ciie2 <- compute_ciie(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = cluster_assignments, 
                       predicted_labels = predicted_labels2, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

metrics_summary <- data.frame(
  Method = c("SelvarClustLasso", "clustvarsel"),
  NRMSE = c(round(nrmse1, 4), round(nrmse2, 4)),
  WNRMSE = c(round(wnrmse1, 4), round(wnrmse2, 4)),
  CIIE = c(round(ciie1, 4), round(ciie2, 4))
)

print(metrics_summary)

```

#### Run full data exp
```{r}
result <- SelvarClustLasso(x = data_list[[8]], 
                                        nbcluster = 2:4,
                             rmodel=c("LB", "LI"), nbcores = detectCores())

for (scenario in 1:8){
  result <- SelvarClustLasso(x = data_list[[scenario]], 
                                        nbcluster = 2:4,
                             rmodel=c("LB", "LI"))
  results_list[[scenario]] <- result}

names(results_list) <- paste0("Scenario_", 1:8)

# Printing summary
for (scenario in names(results_list)) {
  cat("Summary for", scenario, ":\n")
  print(summary(results_list[[scenario]]))
  cat("\n")
}

# saveRDS(results_list, file="full_result_simulated_data_2019_2.rds")
```

#### Run exp missing
```{r} 
set.seed(123)

# Define missing rates
missing_rates <- c(0.01, 0.05, 0.1, 0.15, 0.2)

# Initialize lists to store results
data_missing_all <- list()

data_imputed_selvarmix <- list()
results_list <- list()

results_list_clustvarsel <- list()
data_imputed_clustvarsel <- list()

selvarmix_times <- list()
clustvarsel_times <- list()


for (rate in seq_along(missing_rates)){
  # Introduce missingness
  data_missing <- produce_NA(data_list[[8]], mechanism = "MAR", 
                             perc.missing = missing_rates[rate])$data.incomp
  data_missing_all[[rate]] <- data_missing
  
  # SelvarMix Imputation
  selvarmix_time <- system.time({
    result <- SelvarClustLasso(x = data_missing, 
                               nbcluster = 2:4,
                               rmodel = c("LB", "LI"), 
                               hsize = 3,
                               nbcores = min(8, detectCores(logical = TRUE)))
    data_imputed_selvarmix[[rate]] <- as.data.frame(result$imputedData)
    results_list[[rate]] <- result
  })
  
  selvarmix_times[[rate]] <- as.numeric(selvarmix_time["elapsed"])
  
  # Clustvarsel Imputation
  clustvarsel_time <- system.time({
    data_imputed <- missRanger(data_missing)
    data_imputed_clustvarsel[[rate]] <- data_imputed
    result <- clustvarsel(data_imputed, G = 2:4, search = "greedy",
                         direction = "backward", emModels1 = "V",
                         emModels2 = "VVI", allow.EEE = FALSE,
                         forcetwo = FALSE, parallel = TRUE)
    results_list_clustvarsel[[rate]] <- result
  })
  clustvarsel_times[[rate]] <- as.numeric(clustvarsel_time["elapsed"])
}

# Assign names to lists for clarity
names(data_missing_all) <- paste0("Miss", seq_along(missing_rates))

names(results_list) <- paste0("Miss", seq_along(missing_rates))
names(results_list_clustvarsel) <- paste0("Miss", seq_along(missing_rates))

names(data_imputed_selvarmix) <- paste0("Miss", seq_along(missing_rates))
names(data_imputed_clustvarsel) <- paste0("Miss", seq_along(missing_rates))

names(selvarmix_times) <- paste0("Miss", seq_along(missing_rates))
names(clustvarsel_times) <- paste0("Miss", seq_along(missing_rates))


# Compute NRMSE
selvarmix_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_selvarmix[[i]],
    normalization = "missing"
  )
})

clustvarsel_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_clustvarsel[[i]],
    normalization = "missing"
  )
})

# Compute Weighted NRMSE
selvarmix_weighted_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_weighted_nrmse(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_selvarmix[[i]],
    true_labels = cluster_assignments,
    normalization = "missing"
  )
})

clustvarsel_weighted_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_weighted_nrmse(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_clustvarsel[[i]],
    true_labels = cluster_assignments,
    normalization = "missing"
  )
})

# Compute CIIE
selvarmix_ciie <- sapply(seq_along(missing_rates), function(i) {
  compute_ciie(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]],
    imputed_data = data_imputed_selvarmix[[i]],
    true_labels = cluster_assignments,
    predicted_labels = results_list[[i]]$partition,
    normalization = "missing",
    alpha = 0.4,
    beta = 0.6
  )
})

clustvarsel_ciie <- sapply(seq_along(missing_rates), function(i) {
  compute_ciie(
    original_data = data_list[[8]], 
    missing_data = data_missing_all[[i]],
    imputed_data = data_imputed_clustvarsel[[i]],
    true_labels = cluster_assignments,
    predicted_labels = results_list_clustvarsel[[i]]$model$classification,
    normalization = "missing",
    alpha = 0.4,
    beta = 0.6
  )
})

# Compute ARI 
selvarmix_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    cluster_assignments,  
    results_list[[i]]$partition  
  )
})

clustvarsel_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    cluster_assignments,  
    results_list_clustvarsel[[i]]$model$classification
  )
})

# Printing summary
for (rate in names(results_list)) {
  cat("Summary for", rate, ":\n")
  print(summary(results_list[[rate]]))
  cat("\nClustvarsel Subset for", rate, ":\n")
  print(results_list_clustvarsel[[rate]]$subset)
  cat("\n\n")
}

# Retrieve BIC, number of clusters, and relevant variables
selvarmix_bic <- sapply(results_list, function(x) x$criterionValue)
clustvarsel_bic <- sapply(results_list_clustvarsel, function(x) x$model$bic)

selvarmix_cluster <- sapply(results_list, function(x) x$nbcluster)
clustvarsel_cluster <- sapply(results_list_clustvarsel, function(x) x$model$G)

selvarmix_relevant <- sapply(results_list, function(x) x$S)
clustvarsel_relevant <- sapply(results_list_clustvarsel, function(x) as.numeric(x$subset))

# full result dataframe with new metrics
full_res_df <- data.frame(
  MissingRate = missing_rates,
  SelvarMixTime = unlist(selvarmix_times),
  ClustvarsTime = unlist(clustvarsel_times),
  SelvarMixBIC = selvarmix_bic,
  ClustvarsSelBIC = clustvarsel_bic,
  SelvarMixCluster = selvarmix_cluster,
  ClustvarsCluster = clustvarsel_cluster,
  SelvarMixRelevantVars = sapply(selvarmix_relevant, function(x) paste(x, collapse = ", ")),
  ClustvarsRelevantVars = sapply(clustvarsel_relevant, function(x) paste(x, collapse = ", ")),
  SelvarMixNRMSE = selvarmix_nrmse,
  ClustvarsNRMSE = clustvarsel_nrmse,
  SelvarMixWeightedNRMSE = selvarmix_weighted_nrmse,
  ClustvarsWeightedNRMSE = clustvarsel_weighted_nrmse,
  SelvarMixCIIE = selvarmix_ciie,
  ClustvarsCIIE = clustvarsel_ciie
)


# Plot Running Times
P_time <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixTime, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsTime, color = "Clustvarsel")) +
  labs(title = "Running Times Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Elapsed Time (seconds)",
       color = "Method") +
  mytheme

# # Plot Adjusted Rand Index (ARI)
# P_ARI <- ggplot(full_res_df, aes(x = MissingRate)) +
#   geom_line(aes(y = SelvarMixARI, color = "SelvarMix"), linewidth = 1) +
#   geom_point(aes(y = SelvarMixARI, color = "SelvarMix")) +
#   geom_line(aes(y = ClustvarsARI, color = "Clustvarsel"), linewidth = 1) +
#   geom_point(aes(y = ClustvarsARI, color = "Clustvarsel")) +
#   labs(title = "Adjusted Rand Index Comparison Across Missing Data Rates",
#        x = "Missing Data Rate",
#        y = "Adjusted Rand Index",
#        color = "Method") +
#   ylim(0, 1) +
#   mytheme

# Plot NRMSE
P_NRMSE <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixNRMSE, color = "SelvarMix")) +
  geom_point(aes(y = SelvarMixNRMSE, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsNRMSE, color = "Clustvarsel")) +
  geom_point(aes(y = ClustvarsNRMSE, color = "Clustvarsel")) +
  labs(title = "NRMSE Comparison Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "NRMSE",
       color = "Method") +
  mytheme

# Plot Weighted NRMSE
P_WNRMSE <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixWeightedNRMSE, color = "SelvarMix")) +
  geom_point(aes(y = SelvarMixWeightedNRMSE, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsWeightedNRMSE, color = "Clustvarsel")) +
  geom_point(aes(y = ClustvarsWeightedNRMSE, color = "Clustvarsel")) +
  labs(title = "Weighted NRMSE Comparison Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Weighted NRMSE",
       color = "Method") +
  mytheme

# Plot Clustering-Integrated Imputation Error (CIIE)
P_CIIE <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixCIIE, color = "SelvarMix")) +
  geom_point(aes(y = SelvarMixCIIE, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsCIIE, color = "Clustvarsel")) +
  geom_point(aes(y = ClustvarsCIIE, color = "Clustvarsel")) +
  labs(title = "Clustering-Integrated Imputation Error (CIIE) Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "CIIE",
       color = "Method") +
  mytheme

ggpubr::ggarrange(
  P_time, P_NRMSE, P_WNRMSE, P_CIIE,
  ncol = 2, nrow = 2,
  common.legend = FALSE, 
  legend = "bottom"
)


# saveRDS(results_list, file="selvarmix_full_res_sim_data_2019_missing.rds")
# 
# saveRDS(results_list_clustvarsel, file="clustvarsel_full_res_sim_data_2019_missing.rds")
# 
# saveRDS(P_time, file = "time_plot_sim_data_2019_missing.rds")
# 
# saveRDS(P_ARI, file = "ari_plot_sim_data_2019_missing.rds")
# 
# saveRDS(full_res_df, file = "compare_full_res_sim_data_2019_missing.rds")

```

### Maugis 2012
```{r}
set.seed(123)

# Parameters
n <- 2000
p <- c(0.25, 0.25, 0.2, 0.3)
mu <- rbind(c(0, 0, 0),
            c(-6, 6, 0),
            c(0, 0, 6),
            c(-6, 6, 6))

# Create covariance matrix
A <- rotation_matrix_3d("z", pi/6) %*% rotation_matrix_3d("x", pi/3)
Sigma <- A %*% diag(c(6*sqrt(2), 1, 2)) %*% t(A)
diag_vals <- diag(Sigma)
Sigma <- diag(x = diag_vals)

# Generate mixture data (diagonal form only)
component <- sample(1:4, n, replace = TRUE, prob = p)
X <- matrix(0, nrow = n, ncol = 3)
for (k in 1:4) {
  idx <- which(component == k)
  X[idx,] <- mvrnorm(length(idx), mu = mu[k,], Sigma = Sigma)
}

# Generate fourth and fifth variables
epsilon <- mvrnorm(n, mu = c(0, 0), Sigma = rotation_matrix_2d(pi/6) %*% diag(c(1, 3)) %*% t(rotation_matrix_2d(pi/6)))
Y45 <- cbind(X[,1:2] %*% matrix(c(0.5, 1, 2, 0), nrow = 2) + epsilon + c(-1, 2))

# Generate two noisy variables
noise <- matrix(rnorm(n*2), ncol = 2)

# Combine all variables
data <- cbind(X, Y45, noise)
colnames(data) <- paste0("V", 1:7)
```

#### Run exp normal
```{r}
data_missing <- produce_NA(data, mechanism = "MAR", 
                           perc.missing = 0.2)$data.incomp

result <- SelvarClustLasso(
  x = data_missing, 
  nbcluster = 2:4,
  rmodel = c("LB", "LI"), 
  hsize = 2,
  nbcores = detectCores(logical = TRUE),
  impute_missing = TRUE,
  scale_data = TRUE,
  use_missing_pattern = FALSE
)

data_imputed <- missRanger(data_missing)
result2 <-clustvarsel(data_imputed, G=2:4, search="greedy",
                          direction = "backward", emModels1 = "V", 
                          emModels2 = "VVI", allow.EEE = FALSE, 
                          forcetwo = FALSE, parallel = TRUE)


predicted_labels1 <- result$partition
predicted_labels2 <- result2$model$classification
imputed_data1 <- result$imputedData
similarity_metrics1 <- clustComp(component, predicted_labels1)
similarity_metrics2 <- clustComp(component, predicted_labels2)

# Compute Metrics for SelvarClustLasso
nrmse1 <- compute_nrmse(original_data = data, 
                        missing_data = data_missing, 
                        imputed_data = imputed_data1, 
                        normalization = "missing")

wnrmse1 <- compute_weighted_nrmse(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = component,
                       normalization = "missing")

ciie1 <- compute_ciie(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = component, 
                       predicted_labels = predicted_labels1, 
                       normalization = "missing", 
                       alpha = 0.4, 
                       beta = 0.6)

# Compute Metrics for clustvarsel
nrmse2 <- compute_nrmse(original_data = data, 
                        missing_data = data_missing, 
                        imputed_data = data_imputed, 
                        normalization = "missing")

wnrmse2 <- compute_weighted_nrmse(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = component, 
                       normalization = "missing")

ciie2 <- compute_ciie(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = component, 
                       predicted_labels = predicted_labels2, 
                       normalization = "missing", 
                       alpha = 0.4, 
                       beta = 0.6)

metrics_summary <- data.frame(
  Method = c("SelvarClustLasso", "clustvarsel"),
  NRMSE = c(round(nrmse1, 4), round(nrmse2, 4)),
  WNRMSE = c(round(wnrmse1, 4), round(wnrmse2, 4)),
  CIIE = c(round(ciie1, 4), round(ciie2, 4))
)

print(metrics_summary)

```

#### Run full exp with no scale
```{r}
set.seed(123)
missing_rates <- c(0.01, 0.05, 0.1, 0.15, 0.2)

data_missing_all <- list()

data_imputed_selvarmix <- list()
data_imputed_selvarmix_noscale <- list()
data_imputed_clustvarsel <- list()

results_list <- list()
results_list_noscale <- list()
results_list_clustvarsel <- list()


selvarmix_times <- list()
selvarmix_times_noscale <- list()
clustvarsel_times <- list()

# Experimental conditions
conditions <- list(
  c(impute_missing = TRUE, scale_data = TRUE),  
  c(impute_missing = TRUE, scale_data = FALSE)   # Impute but no scaling
)

for (rate in seq_along(missing_rates)) {
  # Produce missing data
  data_missing <- produce_NA(data, mechanism = "MAR", 
                             perc.missing = missing_rates[rate])$data.incomp
  data_missing_all[[rate]] <- data_missing
  
  # Initialize lists for each condition
  selvarmix_results_by_condition <- list()
  selvarmix_times_by_condition <- list()
  
  # Iterate through experimental conditions
  for (condition_idx in seq_along(conditions)) {
    condition <- conditions[[condition_idx]]
    
    # SelvarMix with different configurations
    selvarmix_time <- system.time({
      result <- SelvarClustLasso(
        x = data_missing, 
        nbcluster = 2:4,
        rmodel = c("LB", "LI"), 
        hsize = 2,
        nbcores = detectCores(logical = TRUE),
        impute_missing = condition["impute_missing"],
        scale_data = condition["scale_data"]
      )
      
      # Store results
      if (condition["scale_data"]){
        data_imputed_selvarmix[[rate]] <- as.data.frame(result$imputedData)
        results_list[[rate]] <- result
      } else if (!condition["scale_data"]){
        data_imputed_selvarmix_noscale[[rate]] <- as.data.frame(result$imputedData)
        results_list_noscale[[rate]] <- result
      }
      
    })
    
    # Store timing
    if (condition["scale_data"]) {
      selvarmix_times[[rate]] <- as.numeric(selvarmix_time["elapsed"])
    } else if (!condition["scale_data"]) {
      selvarmix_times_noscale[[rate]] <- as.numeric(selvarmix_time["elapsed"])
    }}

  # Clustvarsel (for comparison)
  clustvarsel_time <- system.time({
    data_imputed <- missRanger(data_missing)
    data_imputed_clustvarsel[[rate]] <- data_imputed
    result <- clustvarsel(data_imputed, G=2:4, search="greedy",
                          direction = "backward", emModels1 = "V", 
                          emModels2 = "VVI", allow.EEE = FALSE, 
                          forcetwo = FALSE, parallel = TRUE)
    results_list_clustvarsel[[rate]] <- result
  })
  clustvarsel_times[[rate]] <- as.numeric(clustvarsel_time["elapsed"])
}

# Set names for lists
names(data_missing_all) <- paste0("Miss", seq_along(missing_rates))

names(results_list) <- paste0("Miss", seq_along(missing_rates))
names(results_list_noscale) <- paste0("Miss", seq_along(missing_rates)) 
names(results_list_clustvarsel) <- paste0("Miss", seq_along(missing_rates))

names(selvarmix_times_noscale) <- paste0("Miss", seq_along(missing_rates))
names(selvarmix_times) <- paste0("Miss", seq_along(missing_rates))
names(clustvarsel_times) <- paste0("Miss", seq_along(missing_rates))

# Compute NRMSE for all missing rate scenarios
selvarmix_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data, 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_selvarmix[[i]]
  )
})

selvarmix_nrmse_noscale <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data, 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_selvarmix_noscale[[i]]
  )
})

clustvarsel_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data, 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_clustvarsel[[i]]
  )
})

# Compute ARI 
selvarmix_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    component,  
    results_list[[i]]$partition  
  )
})

selvarmix_ari_noscale <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    component, 
    results_list_noscale[[i]]$partition 
  )
})

clustvarsel_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    component,  
    results_list_clustvarsel[[i]]$model$classification
  )
})

# Retrieve result 
selvarmix_bic <- sapply(results_list, function(x) x$criterionValue)
selvarmix_bic_noscale <- sapply(results_list_noscale, function(x) x$criterionValue)
clustvarsel_bic <- sapply(results_list_clustvarsel, function(x) x$model$bic)

selvarmix_cluster <- sapply(results_list, function(x) x$nbcluster)
selvarmix_cluster_noscale <- sapply(results_list_noscale, function(x) x$nbcluster)
clustvarsel_cluster<- sapply(results_list_clustvarsel, function(x) x$model$G)

selvarmix_relevant <- sapply(results_list, function(x) x$S)
selvarmix_relevant_noscale <- sapply(results_list_noscale, function(x) x$S)
clustvarsel_relevant <- sapply(results_list_clustvarsel, function(x) as.numeric(x$subset))


# Create full result dataframe
full_res_df <- data.frame(
  MissingRate = missing_rates,
  SelvarMixTime = unlist(selvarmix_times),
  ClustvarsTime = unlist(clustvarsel_times),
  SelvarMixBIC = selvarmix_bic,
  ClustvarsSelBIC = clustvarsel_bic,
  SelvarMixCluster = selvarmix_cluster,
  ClustvarsCluster = clustvarsel_cluster,
  SelvarMixRelevantVars = sapply(selvarmix_relevant, function(x) paste(x, collapse = ", ")),
  ClustvarsRelevantVars = sapply(clustvarsel_relevant, function(x) paste(x, collapse = ", ")),
  SelvarMixNRMSE = selvarmix_nrmse,
  ClustvarsNRMSE = clustvarsel_nrmse,
  SelvarMixARI = selvarmix_ari,
  ClustvarsARI = clustvarsel_ari
)

full_res_df_w_noscale <- data.frame(
  MissingRate = missing_rates,
  SelvarMixTime = unlist(selvarmix_times),
  SelvarMixTimeNoScale = unlist(selvarmix_times_noscale),
  ClustvarsTime = unlist(clustvarsel_times),
  SelvarMixBIC = selvarmix_bic,
  SelvarMixBICNoScale = selvarmix_bic_noscale,
  ClustvarsSelBIC = clustvarsel_bic,
  SelvarMixCluster = selvarmix_cluster,
  SelvarMixClusterNoScale = selvarmix_cluster_noscale,
  ClustvarsCluster = clustvarsel_cluster,
  SelvarMixRelevantVars = sapply(selvarmix_relevant, 
                                 function(x) paste(x, collapse = ", ")),
  SelvarMixRelevantVarsNoScale = sapply(selvarmix_relevant_noscale, 
                                        function(x) paste(x, collapse = ", ")),
  ClustvarsRelevantVars = sapply(clustvarsel_relevant, 
                                 function(x) paste(x, collapse = ", ")),
  SelvarMixNRMSE = selvarmix_nrmse,
  SelvarMixNRMSENoScale = selvarmix_nrmse_noscale,
  ClustvarsNRMSE = clustvarsel_nrmse,
  SelvarMixARI = selvarmix_ari,
  SelvarMixARINoScale = selvarmix_ari_noscale,
  ClustvarsARI = clustvarsel_ari
)


P_time <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixTime, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsTime, color = "Clustvarsel")) +
  labs(title = "Running Times Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Elapsed Time (seconds)") + mytheme

P_ARI <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixARI, color = "SelvarMix"), linewidth = 1) +
  geom_point(aes(y = SelvarMixARI, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsARI, color = "Clustvarsel"), linewidth = 1) +
  geom_point(aes(y = ClustvarsARI, color = "Clustvarsel")) +
  labs(title = "Adjusted Rand Index Comparison Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Adjusted Rand Index",
       color = "Method") +
  ylim(0, 1) +
  mytheme

ggpubr::ggarrange(P_time, P_ARI,
                               ncol = 1, nrow = 2,
                               common.legend = FALSE, 
                  legend = "bottom")
```


#### Run full exp
```{r}
set.seed(123)
missing_rates <- c(0.01, 0.05, 0.1, 0.15, 0.2)
data_missing_all <- list()

data_imputed_selvarmix <- list()
results_list <- list()

results_list_clustvarsel <- list()
data_imputed_clustvarsel <- list()

selvarmix_times <- list()
clustvarsel_times <- list()

for (rate in seq_along(missing_rates)){
  data_missing <- produce_NA(data, mechanism = "MAR", 
                               perc.missing = missing_rates[rate])$data.incomp
  data_missing_all[[rate]] <- data_missing
  
  # SelvarMix
  selvarmix_time <- system.time({
    result <- SelvarClustLasso(x = data_missing, 
                                          nbcluster = 2:4,
                               rmodel=c("LB", "LI"), hsize = 2,
                               nbcores = detectCores(logical = TRUE))
    data_imputed_selvarmix[[rate]] <- as.data.frame(result$imputedData)
    results_list[[rate]] <- result})
  
  selvarmix_times[[rate]] <- as.numeric(selvarmix_time["elapsed"])
  
  # Clustvarsel
  clustvarsel_time <- system.time({
    data_imputed <- missRanger(data_missing)
    data_imputed_clustvarsel[[rate]] <- data_imputed
    result <- clustvarsel(data_imputed, G=2:4, search="greedy",
                         direction = "backward", emModels1 = "V", 
                         emModels2 = "VVI", allow.EEE = FALSE, 
                         forcetwo = FALSE, parallel = TRUE)
    results_list_clustvarsel[[rate]] <- result
  })
  clustvarsel_times[[rate]] <- as.numeric(clustvarsel_time["elapsed"])
}

# Set names
names(data_missing_all) <- paste0("Miss", seq_along(missing_rates))

names(results_list) <- paste0("Miss", seq_along(missing_rates))
names(results_list_clustvarsel) <- paste0("Miss", seq_along(missing_rates))


names(data_imputed_selvarmix) <- paste0("Miss", seq_along(missing_rates))
names(data_imputed_clustvarsel) <- paste0("Miss", seq_along(missing_rates))

names(selvarmix_times) <- paste0("Miss", seq_along(missing_rates))
names(clustvarsel_times) <- paste0("Miss", seq_along(missing_rates))

# Compute NRMSE for all missing rate scenarios
selvarmix_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data, 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_selvarmix[[i]]
  )
})

clustvarsel_nrmse <- sapply(seq_along(missing_rates), function(i) {
  compute_nrmse(
    original_data = data, 
    missing_data = data_missing_all[[i]], 
    imputed_data = data_imputed_clustvarsel[[i]]
  )
})

# Compute ARI 
selvarmix_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    component,  # true cluster labels
    results_list[[i]]$partition  # estimated cluster labels
  )
})

clustvarsel_ari <- sapply(seq_along(missing_rates), function(i) {
  adjustedRandIndex(
    component,  
    results_list_clustvarsel[[i]]$model$classification
  )
})


# Printing summary
for (rate in names(results_list)) {
  cat("Summary for", rate, ":\n")
  print(summary(results_list[[rate]]))
  cat("\n")
  print(results_list_clustvarsel[[rate]]$subset)
}


# Retrieve result 
selvarmix_bic <- sapply(results_list, function(x) x$criterionValue)
clustvarsel_bic <- sapply(results_list_clustvarsel, function(x) x$model$bic)

selvarmix_cluster <- sapply(results_list, function(x) x$nbcluster)
clustvarsel_cluster<- sapply(results_list_clustvarsel, function(x) x$model$G)

selvarmix_relevant <- sapply(results_list, function(x) x$S)
clustvarsel_relevant <- sapply(results_list_clustvarsel, function(x) as.numeric(x$subset))


# Create full result dataframe
full_res_df <- data.frame(
  MissingRate = missing_rates,
  SelvarMixTime = unlist(selvarmix_times),
  ClustvarsTime = unlist(clustvarsel_times),
  SelvarMixBIC = selvarmix_bic,
  ClustvarsSelBIC = clustvarsel_bic,
  SelvarMixCluster = selvarmix_cluster,
  ClustvarsCluster = clustvarsel_cluster,
  SelvarMixRelevantVars = sapply(selvarmix_relevant, function(x) paste(x, collapse = ", ")),
  ClustvarsRelevantVars = sapply(clustvarsel_relevant, function(x) paste(x, collapse = ", ")),
  SelvarMixNRMSE = selvarmix_nrmse,
  ClustvarsNRMSE = clustvarsel_nrmse,
  SelvarMixARI = selvarmix_ari,
  ClustvarsARI = clustvarsel_ari
)



P_time <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixTime, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsTime, color = "Clustvarsel")) +
  labs(title = "Running Times Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Elapsed Time (seconds)") + mytheme

P_ARI <- ggplot(full_res_df, aes(x = MissingRate)) +
  geom_line(aes(y = SelvarMixARI, color = "SelvarMix"), linewidth = 1) +
  geom_point(aes(y = SelvarMixARI, color = "SelvarMix")) +
  geom_line(aes(y = ClustvarsARI, color = "Clustvarsel"), linewidth = 1) +
  geom_point(aes(y = ClustvarsARI, color = "Clustvarsel")) +
  labs(title = "Adjusted Rand Index Comparison Across Missing Data Rates",
       x = "Missing Data Rate",
       y = "Adjusted Rand Index",
       color = "Method") +
  ylim(0, 1) +
  mytheme

ggpubr::ggarrange(P_time, P_ARI,
                               ncol = 1, nrow = 2,
                               common.legend = FALSE, 
                  legend = "bottom")

# saveRDS(results_list, file="selvarmix_full_res_sim_data_2012_missing.rds")
# 
# saveRDS(results_list_clustvarsel, file="clustvarsel_full_res_sim_data_2012_missing.rds")
# 
# saveRDS(P_time, file = "time_plot_sim_data_2012_missing.rds")
# 
# saveRDS(P_ARI, file = "ari_plot_sim_data_2012_missing.rds")
# 
# saveRDS(full_res_df, file = "compare_full_res_sim_data_2012_missing.rds")

```


## Sensitivity analysis
```{r}
# Set up parameters
data_sen <- list(data, data_list[[8]])
hsize_values  <- c(2, 3, 5, 7)
data_sen_labels <- list(component, cluster_assignments) 
true_S <- list(
    "Dataset_1" = c("1", "2", "3"),
    "Dataset_2" = c("1", "2"))

# Missing rates per dataset
missing_rates_list <- list(
  c(0.01, 0.05, 0.1, 0.15, 0.2),  
  c(0.2)                  
)

# Number of simulation runs
n_runs <- 20  

# Initialize the complete nested list structure
# Structure: Dataset -> MissingRate -> HSize -> Run -> Result
sensitivity_results <- vector("list", length(data_sen))
names(sensitivity_results) <- paste0("Dataset_", seq_along(data_sen))

for(i in seq_along(data_sen)) {
  current_missing_rates <- missing_rates_list[[i]]
  sensitivity_results[[i]] <- vector("list", length(current_missing_rates))
  names(sensitivity_results[[i]]) <- paste0("MissingRate_", current_missing_rates)
  
  for(j in seq_along(current_missing_rates)) {
    sensitivity_results[[i]][[j]] <- vector("list", length(hsize_values))
    names(sensitivity_results[[i]][[j]]) <- paste0("h", hsize_values)
    
    for(k in seq_along(hsize_values)) {
      sensitivity_results[[i]][[j]][[k]] <- vector("list", n_runs)
      names(sensitivity_results[[i]][[j]][[k]]) <- paste0("Run_", 1:n_runs)
    }
  }
}

# Timing tracking
timing_results <- data.frame(
  Dataset = character(),
  Missing_Rate = numeric(),
  HSize = numeric(),
  Run = numeric(),
  Run_Time_Seconds = numeric(),
  stringsAsFactors = FALSE
)

# Create results directory if it doesn't exist
dir.create("sensitivity_results", showWarnings = FALSE)

# Set cores
nbcores_to_use <- min(6, parallel::detectCores(logical = TRUE) - 1)
cat("Using", nbcores_to_use, "cores for computation\n")

total_start_time <- Sys.time()

# Start the simulation runs
for (run_idx in 1:n_runs) {
  cat("\n=== Starting Run", run_idx, "===\n")
  
  # Start track each run time 
  run_start_time <- Sys.time()
  
  for (dat_idx in seq_along(data_sen)) {
    current_data <- data_sen[[dat_idx]]
    current_labels <- data_sen_labels[[dat_idx]]
    num_vars <- ncol(current_data)
    
    cat("\nProcessing Dataset", dat_idx, "with", num_vars, "variables.\n")
    
    current_missing_rates <- missing_rates_list[[dat_idx]]
    
    for (miss_idx in seq_along(current_missing_rates)) {
      miss_rate <- current_missing_rates[miss_idx]
      cat("\n  Missing Rate:", miss_rate, "\n")
      
      for (h_idx in seq_along(hsize_values)) {
        h <- hsize_values[h_idx]
        cat("    Processing hsize:", h, "\n")
        
        # Start track config time 
        config_start_time <- Sys.time()
        
        # Check if the result for this run already exists to allow resuming
        result_file <- file.path("sensitivity_results", paste0("dataset_", dat_idx, "_miss_", miss_rate, "_h_", h, "_run_", run_idx, "_results.rds"))
        if (file.exists(result_file)) {
          cat("    Loading existing results for run", run_idx, "\n")
          sensitivity_results[[dat_idx]][[miss_idx]][[h_idx]][[run_idx]] <- readRDS(result_file)
          next
        }
        
        tryCatch({
          # Generate missing data
          data_missing <- produce_NA(current_data, 
                                     mechanism = "MAR", 
                                     perc.missing = miss_rate)$data.incomp
          
          # Run SelvarClustLasso
          selvar_result <- SelvarClustLasso(
            x = data_missing, 
            nbcluster = 2:4,
            rmodel = c("LB", "LI"), 
            hsize = h, 
            nbcores = nbcores_to_use,
            impute_missing = TRUE,
            scale_data = TRUE
          )
          
          config_time <- as.numeric(difftime(Sys.time(), 
                                             config_start_time, 
                                             units = "secs"))
          
          # Store timing results
          timing_results <- rbind(timing_results, data.frame(
            Dataset = paste0("Dataset_", dat_idx),
            Missing_Rate = miss_rate,
            HSize = h,
            Run = run_idx,
            Run_Time_Seconds = config_time,
            stringsAsFactors = FALSE
          ))
          
          # Extract results and compute metrics
          imputed_data_selvar <- selvar_result$imputedData
          predicted_labels_selvar <- selvar_result$partition
          
          # Compute all metrics with individual error handling
          ari_selvar <- tryCatch({
            adjustedRandIndex(current_labels, predicted_labels_selvar)
          }, error = function(e) {
            cat("    Warning: Failed to compute ARI:", conditionMessage(e), "\n")
            return(NA)
          })
          
          nrmse_selvar <- tryCatch({
            compute_nrmse(
              original_data = current_data, 
              missing_data = data_missing, 
              imputed_data = imputed_data_selvar, 
              normalization = "missing"
            )
          }, error = function(e) {
            cat("    Warning: Failed to compute NRMSE:", conditionMessage(e), "\n")
            return(NA)
          })
          
          wnrmse_selvar <- tryCatch({
            compute_weighted_nrmse(
              original_data = current_data, 
              missing_data = data_missing, 
              imputed_data = imputed_data_selvar, 
              true_labels = current_labels,
              normalization = "missing"
            )
          }, error = function(e) {
            cat("    Warning: Failed to compute WNRMSE:", conditionMessage(e), "\n")
            return(NA)
          })
          
          ciie_selvar <- tryCatch({
            compute_ciie(
              original_data = current_data, 
              missing_data = data_missing, 
              imputed_data = imputed_data_selvar, 
              true_labels = current_labels, 
              predicted_labels = predicted_labels_selvar, 
              normalization = "missing", 
              alpha = 0.5, 
              beta = 0.5
            )
          }, error = function(e) {
            cat("    Warning: Failed to compute CIIE:", conditionMessage(e), "\n")
            return(NA)
          })
          
          # Create results dataframe
          result <- data.frame(
            Run = run_idx,
            Dataset = paste0("Dataset_", dat_idx),
            Num_Variables = num_vars,
            Missing_Rate = miss_rate,
            HSize = h,
            Method = "SelvarClustLasso",
            NRMSE = round(nrmse_selvar, 4),
            WNRMSE = round(wnrmse_selvar, 4),
            CIIE = round(ciie_selvar, 4),
            BIC = selvar_result$criterionValue,
            Num_Clusters = selvar_result$nbcluster,  
            Relevant_Variables = paste(selvar_result$S, collapse = ", "),
            ARI = round(ari_selvar, 4),
            stringsAsFactors = FALSE
          )
          
          result$Run_Time_Seconds <- config_time
          
          # Store result
          sensitivity_results[[dat_idx]][[miss_idx]][[h_idx]][[run_idx]] <- result
          
          # Save intermediate results for this run
          saveRDS(sensitivity_results[[dat_idx]][[miss_idx]][[h_idx]][[run_idx]], result_file)
          cat("    Saved results for run", run_idx, "\n")
          print(result)
          cat("    Completed in", round(config_time, 2), "seconds\n")
          
          # Cleanup
          gc()
          
        }, error = function(e) {
          cat("\n    Error occurred for hsize =", h, "in run", run_idx, ":\n")
          cat("    Error message:", conditionMessage(e), "\n")
        })
      }
    }
  }
  
  run_time <- as.numeric(difftime(Sys.time(), run_start_time, units = "secs"))
  cat("=== Completed Run", run_idx, "in", round(run_time, 2), "seconds ===\n")
}

total_time <- as.numeric(difftime(Sys.time(), total_start_time, units = "secs"))

# Function to transform and compute aggregated metrics
transform_sensitivity_results <- function(sensitivity_results, 
                                          timing_results,
                                          n_runs, 
                                          true_num_cluster = 4,
                                          true_relevant_vars = true_S) {
  # Initialize an empty list to store all results
  all_results <- list()
  
  # Loop through each dataset
  for(dat_idx in seq_along(sensitivity_results)) {
    dataset_results <- sensitivity_results[[dat_idx]]
    
    # Loop through each missing rate
    for(miss_idx in seq_along(dataset_results)) {
      missing_rate_results <- dataset_results[[miss_idx]]
      
      # Loop through each h-size
      for(h_idx in seq_along(missing_rate_results)) {
        h_results <- missing_rate_results[[h_idx]]
        
        # Loop through each run
        for(run_idx in seq_along(h_results)) {
          result <- h_results[[run_idx]]
          
          # Only add non-null results
          if(!is.null(result)) {
            all_results[[length(all_results) + 1]] <- result
          }
        }
      }
    }
  }
  
  # Combine into a single tibble
  results_tibble <- bind_rows(all_results)|>
    mutate(across(c(Dataset, Method, Relevant_Variables), as.factor))|>
    mutate(across(c(Num_Variables, Missing_Rate, HSize, 
                   NRMSE, WNRMSE, CIIE, BIC, 
                   Num_Clusters, ARI), as.numeric))
  
  results_tibble <- results_tibble |>
    mutate(
      Correct_Variables = map2_int(Dataset, Relevant_Variables, ~ {
        true_vars <- true_relevant_vars[[.x]]
        selected_vars <- str_split(.y, ",\\s*")[[1]]
        if(length(selected_vars) != length(true_vars)) {
          return(0)
        } else {
          return(all(sort(selected_vars) == sort(true_vars)) * 1)
        }
      })
    )
  
  # Compute metric summaries
  freq_cluster <- results_tibble |>
    mutate(Correct_Clusters = ifelse(Num_Clusters == true_num_cluster, 1, 0)) |>
    group_by(Dataset, Missing_Rate, HSize, Method) |>
    summarise(
      Avg_NRMSE = mean(NRMSE, na.rm = TRUE),
      SD_NRMSE = sd(NRMSE, na.rm = TRUE),
      
      Avg_WNRMSE = mean(WNRMSE, na.rm = TRUE),
      SD_WNRMSE = sd(WNRMSE, na.rm = TRUE),
      
      Avg_CIIE = mean(CIIE, na.rm = TRUE),
      SD_CIIE = sd(CIIE, na.rm = TRUE),
      
      Avg_BIC = mean(BIC, na.rm = TRUE),
      SD_BIC = sd(BIC, na.rm = TRUE),
      
      Avg_ARI = mean(ARI, na.rm = TRUE),
      SD_ARI = sd(ARI, na.rm = TRUE),
      
      freq_num_cluster = sum(Correct_Clusters, na.rm = TRUE),
      
      freq_correct_variables = sum(Correct_Variables, na.rm = TRUE),
      
      .groups = 'drop'
    ) |>
    arrange(Dataset, Missing_Rate, HSize)
  
  # Compute timing summaries
  timing_summary <- timing_results |>
    group_by(Dataset, Missing_Rate, HSize) |>
    summarise(
      Avg_Run_Time = mean(Run_Time_Seconds, na.rm = TRUE),
      SD_Run_Time = sd(Run_Time_Seconds, na.rm = TRUE),
      .groups = 'drop'
    )
  
  freq_cluster <- freq_cluster |> 
    left_join(timing_summary, by = c("Dataset", "Missing_Rate", "HSize"))
  
  return(freq_cluster)
}

# Transform and aggregate the results
results_tibble <- transform_sensitivity_results(sensitivity_results, 
                                                timing_results,
                                                n_runs)

# Save results
final_results_file <- file.path("sensitivity_results", "averaged_sensitivity_results.rds")
saveRDS(results_tibble, final_results_file)
cat("\nAnalysis complete. Averaged results saved to:", final_results_file, "\n")
cat("\nTotal execution time:", round(total_time/3600, 2), "hours\n")
cat("Average time per run:", round(total_time/n_runs/60, 2), "minutes\n\n")

# df <- readRDS(here("MissingData_MOE\\sensitivity_results\\averaged_sensitivity_results.rds"))

```

## Plotting

```{r}
theme_plot <- function(base_size = 12) {
  theme_minimal(base_size = base_size) %+replace%
    theme(
      # Text elements
      plot.title = element_text(
        size = rel(1.2),
        face = "bold",
        hjust = 0.5,
        margin = margin(b = 15)
      ),
      plot.subtitle = element_text(
        size = rel(0.95),
        hjust = 0.5,
        margin = margin(b = 10)
      ),
      axis.title = element_text(size = rel(1)),
      axis.text = element_text(size = rel(0.9)),
      
      # Legend formatting
      legend.position = "top",
      legend.title = element_text(size = rel(0.95)),
      legend.text = element_text(size = rel(0.85)),
      legend.box.spacing = unit(0.5, "lines"),
      
      # Grid lines
      panel.grid.major = element_line(color = "gray90", 
                                      size = 0.2),
      panel.grid.minor = element_blank(),
      
      # Facet formatting
      strip.text = element_text(
        size = rel(0.95),
        face = "bold",
        margin = margin(b = 5, t = 5)
      ),
      
      # Space around the plot 
      plot.margin = margin(t = 20, r = 20, b = 20, l = 20)
    )
}

metric_colors <- c(
  "WNRMSE" = "#0077BB",  # Blue
  "ARI"    = "#EE7733",  # Orange
  "CIIE"   = "#009988"   # Teal
)

aggregated_metrics <- results_tibble|>
  group_by(Dataset, HSize)|>
  summarise(
    # Calculate the mean of average metrics across Missing_Rate
    Mean_Avg_WNRMSE = mean(Avg_WNRMSE, na.rm = TRUE),
    Mean_Avg_ARI = mean(Avg_ARI, na.rm = TRUE),
    Mean_Avg_CIIE = mean(Avg_CIIE, na.rm = TRUE),
    
    # Calculate the pooled standard deviation
    Pooled_SD_WNRMSE = sqrt(mean(SD_WNRMSE^2, na.rm = TRUE)),
    Pooled_SD_ARI = sqrt(mean(SD_ARI^2, na.rm = TRUE)),
    Pooled_SD_CIIE = sqrt(mean(SD_CIIE^2, na.rm = TRUE)),
    
    # Optionally, calculate the number of Missing_Rate values
    Num_Missing_Rate = n_distinct(Missing_Rate),
    
    .groups = 'drop'
  )


plot_data <- aggregated_metrics|>
  select(Dataset, HSize, Mean_Avg_WNRMSE, Mean_Avg_ARI, Mean_Avg_CIIE,
         Pooled_SD_WNRMSE, Pooled_SD_ARI, Pooled_SD_CIIE)|>
  pivot_longer(
    cols = starts_with("Mean_Avg_"),
    names_to = "Metric",
    names_prefix = "Mean_Avg_",
    values_to = "Mean"
  )|>
  mutate(
    SD = case_when(
      Metric == "WNRMSE" ~ Pooled_SD_WNRMSE,
      Metric == "ARI"     ~ Pooled_SD_ARI,
      Metric == "CIIE"    ~ Pooled_SD_CIIE,
      TRUE                ~ NA_real_
    )
  )|>
  select(Dataset, HSize, Metric, Mean, SD)

plot_data <- plot_data|>
  complete(Dataset, HSize, Metric, fill = list(Mean = NA_real_, SD = NA_real_))

performance_plot <- ggplot(plot_data, aes(x = Dataset, y = Mean, fill = Metric)) +
  # Add bars
  geom_bar(
    position = position_dodge(width = 0.85),
    stat = "identity",
    width = 0.75,
    alpha = 0.9 
  ) +
  # Add error bars
  geom_errorbar(
    aes(ymin = Mean - SD, ymax = Mean + SD),
    position = position_dodge(width = 0.85),
    width = 0.25,
    size = 0.3,
    color = "black"
  ) +
  # Facet with improved spacing
  facet_wrap(~ HSize, ncol = 2, scales = "fixed") +
  # Apply color palette
  scale_fill_manual(values = metric_colors) +
  # Improve labels
  labs(
    title = "Model Performance Metrics Across Datasets and HSize",
    subtitle = "Mean WNRMSE, ARI, and CIIE with Standard Deviation",
    x = "Dataset",
    y = "Mean Metric Value",
    fill = "Metric"
  ) +
  # Set y-axis limits with some padding
  scale_y_continuous(
    limits = c(0, 1),
    breaks = seq(0, 1, 0.25),
    expand = expansion(mult = c(0.02, 0.08))
  ) +
  theme_plot()
  
# Frequency of choosing correct clusters and S
aggregated_frequency <- results_tibble |>
  group_by(Dataset, HSize) |>
  summarise(
    Total_Correct_Clusters = sum(freq_num_cluster, na.rm = TRUE),
    Total_Correct_Variables = sum(freq_correct_variables, na.rm = TRUE),
    Total_Runs = n_runs * n_distinct(Missing_Rate),
    .groups = 'drop'
  ) |>
  mutate(
    Proportion_Correct_Clusters = Total_Correct_Clusters / Total_Runs,
    Proportion_Correct_Variables = Total_Correct_Variables / Total_Runs
  )

frequency_plot_data <- aggregated_frequency |>
  select(Dataset, HSize, Proportion_Correct_Clusters, Proportion_Correct_Variables) |>
  pivot_longer(
    cols = starts_with("Proportion_"),
    names_to = "Frequency_Metric",
    values_to = "Proportion"
  ) |>
  mutate(
    Frequency_Metric = case_when(
      Frequency_Metric == "Proportion_Correct_Clusters" ~ "Correct Number of Clusters",
      Frequency_Metric == "Proportion_Correct_Variables" ~ "Correct Relevant Variables",
      TRUE ~ Frequency_Metric
    )
  ) |>
  mutate(
    HSize = factor(HSize),
    Dataset = factor(Dataset),
    Frequency_Metric = factor(Frequency_Metric, levels = c("Correct Number of Clusters", "Correct Relevant Variables"))
  )

frequency_colors <- c(
  "Correct Number of Clusters" = "#0077BB", 
  "Correct Relevant Variables" = "#EE7733" 
)

frequency_plot <- ggplot(frequency_plot_data, aes(x = Dataset, y = Proportion, fill = Frequency_Metric)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_text(aes(label = percent(Proportion, accuracy = 1)),
            position = position_dodge(width = 0.8),
            vjust = -0.5,
            size = 3) +
  facet_wrap(~ HSize, ncol = 2) +
  scale_fill_manual(values = frequency_colors) +
  scale_y_continuous(
    labels = percent_format(accuracy = 1),
    limits = c(0, 1.1),
    breaks = seq(0, 1, 0.2),
    expand = expansion(mult = c(0.02, 0.1))  
  ) +
  labs(
    title = "Frequency of Correct Model Selections Across HSize",
    subtitle = "Comparison of Correct Number of Clusters and Relevant Variables",
    x = "Dataset",
    y = "Proportion of Correct Selections",
    fill = "Frequency Metric"
  ) + theme_plot()

print(frequency_plot)
``` 

## Full analysis
### Parallel version
```{r}
set.seed(123)

# Configuration -----------------------------------------------------------
data_sen <- list(data, data_list[[8]])
data_sen_labels <- list(component, cluster_assignments) 
true_S <- list(Dataset_1 = c("1", "2", "3"), Dataset_2 = c("1", "2"))
true_num_clusters <- list(Dataset_1 = 4, Dataset_2 = 4)
hsize_per_dataset <- c(2, 2)
missing_rates <- c(0, 0.01, 0.05, 0.1, 0.15, 0.2)
n_runs <- 10
models <- c("SelvarClustLasso", "Clustvarsel")

# Core setup --------------------------------------------------------------
total_cores <- detectCores()
available_cores <- max(1, total_cores - 2)
cl <- makeCluster(available_cores)
registerDoParallel(cl)

# Create results directory in main process and workers
dir.create("sensitivity_results", showWarnings = FALSE)
clusterEvalQ(cl, dir.create("sensitivity_results", showWarnings = FALSE))

# Create parameter grid for all combinations
task_grid <- expand.grid(
  run_idx = 1:n_runs,
  dat_idx = seq_along(data_sen),
  miss_rate = missing_rates,
  model = models
)

# Main parallel computation -----------------------------------------------
results <- foreach(task = 1:nrow(task_grid), .combine = rbind,
                   .packages = c("dplyr", "stringr", "missRanger", 
                                "clustvarsel", "SelvarMix", "aricode",
                                "mclust")) %dopar% {
  
  # Extract parameters from task grid
  run_idx <- task_grid$run_idx[task]
  dat_idx <- task_grid$dat_idx[task]
  miss_rate <- task_grid$miss_rate[task]
  model_name <- as.character(task_grid$model[task])
  
  # Dataset-specific parameters
  current_data <- data_sen[[dat_idx]]
  current_labels <- data_sen_labels[[dat_idx]]
  fixed_hsize <- hsize_per_dataset[dat_idx]
  dataset_name <- paste0("Dataset_", dat_idx)
  result_file <- file.path(
    "sensitivity_results",
    sprintf("dataset_%d_miss_%s_model_%s_run_%d.rds",
            dat_idx, miss_rate, model_name, run_idx)
  )
  
  # Skip existing results
  if (file.exists(result_file)) return(NULL)
  
  tryCatch({
    # Create missing data
    data_missing <- if (miss_rate == 0) {
      current_data
    } else {
      produce_NA(current_data, mechanism = "MAR", 
                perc.missing = miss_rate)$data.incomp
    }
    
    # Model execution
    start_time <- Sys.time()
    
    if (model_name == "SelvarClustLasso") {
      model_result <- SelvarClustLasso(
        x = data_missing,
        nbcluster = 2:4,
        rmodel = c("LB", "LI"),
        hsize = fixed_hsize,
        nbcores = 1,
        impute_missing = (miss_rate > 0),
        scale_data = TRUE
      )
      
      imputed_data <- model_result$imputedData
      predicted_labels <- model_result$partition
      relevant_vars <- paste(model_result$S, collapse = ", ")
      bic <- model_result$criterionValue
      n_clusters <- model_result$nbcluster
      
    } else if (model_name == "Clustvarsel") {
      data_imputed <- if (miss_rate == 0) data_missing else missRanger(data_missing)
      
      model_result <- clustvarsel(
        data_imputed,
        G = 2:4,
        search = "greedy",
        direction = "backward",
        emModels1 = "V",
        emModels2 = "VVI",
        allow.EEE = FALSE,
        forcetwo = FALSE,
        parallel = FALSE  
      )
      
      imputed_data <- data_imputed
      predicted_labels <- model_result$model$classification
      relevant_vars <- paste(model_result$subset, collapse = ", ")
      bic <- model_result$model$bic
      n_clusters <- model_result$model$G
    }
    
    # Calculate metrics
    compute_metric <- function(f) {
      tryCatch(f(), error = function(e) NA)
    }
    
    ari <- compute_metric(function() adjustedRandIndex(current_labels, predicted_labels))
    nrmse <- compute_metric(function() compute_nrmse(current_data, data_missing, imputed_data))
    w_nrmse <- compute_metric(function() compute_weighted_nrmse(current_data, data_missing, imputed_data, current_labels))
    ciie <- compute_metric(function() compute_ciie(current_data, data_missing, imputed_data, current_labels, predicted_labels))
    
    # Create result object
    result <- data.frame(
      Run = run_idx,
      Dataset = dataset_name,
      Missing_Rate = miss_rate,
      Model = model_name,
      HSize = fixed_hsize,
      Num_Variables = ncol(current_data),
      NRMSE = round(nrmse, 4),
      WNRMSE = round(w_nrmse, 4),
      CIIE = round(ciie, 4),
      BIC = round(bic, 2),
      Num_Clusters = n_clusters,
      Relevant_Variables = relevant_vars,
      ARI = round(ari, 4),
      Run_Time_Seconds = round(difftime(Sys.time(), start_time, units = "secs"), 2),
      stringsAsFactors = FALSE
    )
    
    # Save individual result
    saveRDS(result, result_file)
    result
    
  }, error = function(e) {
    message(sprintf("Error in task %d: %s", task, conditionMessage(e)))
    NULL
  })
}

# Cleanup parallel workers
stopCluster(cl)

# Post-processing ---------------------------------------------------------
result_files <- list.files("sensitivity_results", pattern = "\\.rds$", full.names = TRUE)
all_results <- lapply(result_files, readRDS) |> bind_rows()

saveRDS(all_results, file = "sensitivity_results/aggregated_results_10_runs.rds")
write.csv(all_results, file = "sensitivity_results/aggregated_results_10_runs.csv", row.names = FALSE)
```


## Consistency
```{r}
n_runs <- 5
# True values
true_clusters <- 4
true_relevant_vars <- c(1, 2)

correct_cluster_count <- 0
correct_variable_count <- 0

for (i in seq_len(n_runs)) {
  # Run SelvarClustLasso
  data_missing <- produce_NA(data_list[[8]], mechanism = "MAR", 
                           perc.missing = 0.15)$data.incomp
  result <- SelvarClustLasso(x = data_missing, 
                             nbcluster = 2:4,
                             rmodel = c("LB", "LI"), 
                             hsize = 2,
                             nbcores = min(6, detectCores(logical = TRUE)),
                             impute_missing = TRUE,
                             scale_data = TRUE)
  
  chosen_clusters <- result$nbcluster
  chosen_variables <- result$S
  
  if (chosen_clusters == true_clusters) {
    correct_cluster_count <- correct_cluster_count + 1
  }
  
  if (length(chosen_variables) == length(true_relevant_vars) && 
      all(sort(chosen_variables) == sort(true_relevant_vars))) {
    correct_variable_count <- correct_variable_count + 1
  }
}

cluster_correct_frequency <- correct_cluster_count / n_runs
variable_correct_frequency <- correct_variable_count / n_runs

cat("Frequency of correctly chosen number of clusters (4):", cluster_correct_frequency, "\n")
cat("Frequency of correctly chosen relevant variables (1 and 2):", variable_correct_frequency, "\n")
```


## Loading result
```{r}
# res_2019 <- readRDS("result_simulated_data_2019.rds")
# res_2019_miss <- readRDS("result_simulated_data_2019_missing.rds")
# res_2012_miss <- readRDS("result_simulated_data_2012_missing.rds")
# full_res_2019_miss <- readRDS("full_result_simulated_data_2019_2_missing.rds")
# full_res_2012_miss <- readRDS("full_result_simulated_data_2012_missing.rds")

full_res_df <- readRDS("result\\maugis_2012\\compare_full_res_sim_data_2012_missing.rds")
```


## Testing
### MixAll vs Mixmod
```{r}
model <- clusterDiagGaussian(data=data_list$Scenario_6, nbCluster=2:4
                            , models=c( "gaussian_pk_sjk")
                            , strategy = rep_mixmod_strategy,
                            criterion="BIC", nbCore = detectCores())

model2 <- mixmodCluster(as.data.frame(data_list$Scenario_6), 2:4, 
                        models=mixmodGaussianModel(family = "diagonal"))
```


### Compare clustering strategy
```{r}
# Function to run clustering with specific strategy parameters
run_clustering <- function(data, init_method, init_algo, num_clusters = 2:4) {
  rep_mixmod_strategy <- clusterStrategy(
    nbTry = 2,
    nbInit = 50,
    initMethod = init_method,
    initAlgo = init_algo,
    nbInitIteration = 10,
    initEpsilon = 1e-4,
    nbShortRun = 10,
    shortRunAlgo = "EM",
    nbShortIteration = 100,
    shortEpsilon = 1e-7,
    longRunAlgo = "EM",
    nbLongIteration = 200,
    longEpsilon = 1e-8
  )
  
  model <- clusterDiagGaussian(
    data = data, 
    nbCluster = num_clusters,
    models = "gaussian_pk_sjk",
    strategy = rep_mixmod_strategy,
    criterion = "BIC", 
    nbCore = detectCores()
  )
  
  return(model)
}

# Function to perform multiple runs and analyze results
analyze_clustering_strategies <- function(data, num_runs = 50) {
  # Initialize results storage
  strategies <- expand.grid(
    init_method = c("random", "class"),
    init_algo = c("EM", "SEM")
  )
  
  # Storage for results
  likelihood_winner <- character(num_runs)
  correct_k_winner <- character(num_runs)
  
  # Perform multiple runs
  for(j in 1:num_runs) {
    # Store log-likelihoods 
    likelihoods <- numeric(nrow(strategies))
    k_selections <- integer(nrow(strategies))
    
    # Run each strategy
    for(i in 1:nrow(strategies)) {
      method <- as.character(strategies$init_method[i])
      algo <- as.character(strategies$init_algo[i])
      
      model <- run_clustering(
        data = data, 
        init_method = method, 
        init_algo = algo
      )
      
      likelihoods[i] <- model@lnLikelihood
      k_selections[i] <- model@nbCluster
    }
    
    # Determine strategy with highest likelihood
    likelihood_winner[j] <- apply(strategies, 1, paste, collapse="_")[which.max(likelihoods)]
    
    # Determine strategy with correct K (K=4)
    correct_k_winner[j] <- apply(strategies, 1, paste, collapse="_")[which(k_selections == 4)]
  }
  
  # Calculate proportions
  likelihood_prop <- prop.table(table(likelihood_winner))
  correct_k_prop <- prop.table(table(correct_k_winner))
  
  # Combine results
  return(list(
    likelihood_proportions = likelihood_prop,
    correct_k_proportions = correct_k_prop
  ))
}

# Run the analysis
strategy_results <- analyze_clustering_strategies(data_list$Scenario_8)

cat("Proportion of Runs with Highest Likelihood:\n")
print(strategy_results$likelihood_proportions)

cat("\nProportion of Runs with Correct Cluster Number (K=4):\n")
print(strategy_results$correct_k_proportions)

```



### SR model vs SRUW reg
```{r}
start_time_clustvarsel <- Sys.time()
result1 <- clustvarsel(data_list[[8]], G=2:4, search="greedy",
                       direction = "backward", emModels1 = "V", 
                       emModels2 = "VVI", allow.EEE = FALSE, forcetwo = FALSE)
end_time_clustvarsel <- Sys.time()
time_clustvarsel <- difftime(end_time_clustvarsel, 
                             start_time_clustvarsel, units = "secs")

start_time_selvarclustlasso <- Sys.time()
result2 <- SelvarClustLasso(x = data_list[[8]], nbcluster = 2:4,
                             rmodel=c("LB", "LI"))
end_time_selvarclustlasso <- Sys.time()
time_selvarclustlasso <- difftime(end_time_selvarclustlasso, start_time_selvarclustlasso, units = "secs")

cat("Running time for clustvarsel:", time_clustvarsel, "seconds\n")
cat("Running time for SelvarClustLasso:", time_selvarclustlasso, "seconds\n")

running_times_df <- data.frame(
  Method = c("clustvarsel", "SelvarClustLasso"),
  Running_Time_Seconds = c(
    as.numeric(time_clustvarsel), 
    as.numeric(time_selvarclustlasso)
  ))

# saveRDS(running_times_df, "running_times_comparison_2019.rds")
```


## MNAR
### Without C
```{r}
data_missing <- produce_NA(data_list[[8]], mechanism = "MNAR", 
                           perc.missing = 0.2)$data.incomp

result <- SelvarClustLasso(
  x = data_missing, 
  nbcluster = 2:4,
  rmodel = c("LB", "LI"), 
  hsize = 2,
  nbcores = detectCores(logical = TRUE),
  impute_missing = TRUE,
  scale_data = TRUE,
  use_missing_pattern = TRUE
)

data_imputed <- missRanger(data_missing)
result2 <-clustvarsel(data_imputed, G=2:4, search="greedy",
                          direction = "backward", emModels1 = "V", 
                          emModels2 = "VVI", allow.EEE = FALSE, 
                          forcetwo = FALSE, parallel = TRUE)


predicted_labels1 <- result$partition
predicted_labels2 <- result2$model$classification
imputed_data1 <- result$imputedData
data_imputed <- as.matrix(data_imputed)

similarity_metrics1 <- clustComp(cluster_assignments, predicted_labels1)
similarity_metrics2 <- clustComp(cluster_assignments, predicted_labels2)

# Compute Metrics for SelvarClustLasso
nrmse1 <- compute_nrmse(original_data = data_list[[8]], 
                        missing_data = data_missing, 
                        imputed_data = imputed_data1, 
                        normalization = "missing")

wnrmse1 <- compute_weighted_nrmse(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = cluster_assignments,
                       normalization = "missing")

ciie1 <- compute_ciie(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = cluster_assignments, 
                       predicted_labels = predicted_labels1, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

# Compute Metrics for clustvarsel
nrmse2 <- compute_nrmse(original_data = data_list[[8]], 
                        missing_data = data_missing, 
                        imputed_data = data_imputed, 
                        normalization = "missing")

wnrmse2 <- compute_weighted_nrmse(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = cluster_assignments, 
                       normalization = "missing")

ciie2 <- compute_ciie(original_data = data_list[[8]], 
                       missing_data = data_missing, 
                       imputed_data = data_imputed, 
                       true_labels = cluster_assignments, 
                       predicted_labels = predicted_labels2, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

metrics_summary <- data.frame(
  Method = c("SelvarClustLasso", "clustvarsel"),
  NRMSE = c(round(nrmse1, 4), round(nrmse2, 4)),
  WNRMSE = c(round(wnrmse1, 4), round(wnrmse2, 4)),
  CIIE = c(round(ciie1, 4), round(ciie2, 4))
)

print(metrics_summary)
```

### With C
```{r}
data_missing <- produce_NA(data_list[[8]], mechanism = "MNAR", 
                           perc.missing = 0.2)$data.incomp


result_wo_C <- SelvarClustLasso(
  x = data_missing, 
  nbcluster = 2:4,
  rmodel = c("LB", "LI"), 
  hsize = 2,
  nbcores = detectCores(logical = TRUE),
  impute_missing = TRUE,
  scale_data = TRUE,
  use_missing_pattern = FALSE
)

result_w_C <- SelvarClustLasso(
  x = data_missing, 
  nbcluster = 2:4,
  rmodel = c("LB", "LI"), 
  hsize = 2,
  nbcores = detectCores(logical = TRUE),
  impute_missing = TRUE,
  scale_data = TRUE,
  use_missing_pattern = TRUE
)

predicted_labels1 <- result_wo_C$partition
# predicted_labels2 <- result_w_C$partition

predicted_labels2<- apply(result_w_C$proba_corrected, 1, which.max)

imputed_data1 <- result_wo_C$imputedData
imputed_data2 <- result_w_C$imputedData



similarity_metrics1 <- clustComp(cluster_assignments, predicted_labels1)
similarity_metrics2 <- clustComp(cluster_assignments, predicted_labels2)

# Compute Metrics for model wo C
nrmse1 <- compute_nrmse(original_data = data, 
                        missing_data = data_missing, 
                        imputed_data = imputed_data1, 
                        normalization = "missing")

wnrmse1 <- compute_weighted_nrmse(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = component,
                       normalization = "missing")

ciie1 <- compute_ciie(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = imputed_data1, 
                       true_labels = component, 
                       predicted_labels = predicted_labels1, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

# Compute Metrics for model w C
nrmse2 <- compute_nrmse(original_data = data, 
                        missing_data = data_missing, 
                        imputed_data = imputed_data2, 
                        normalization = "missing")

wnrmse2 <- compute_weighted_nrmse(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = imputed_data2, 
                       true_labels = component, 
                       normalization = "missing")

ciie2 <- compute_ciie(original_data = data, 
                       missing_data = data_missing, 
                       imputed_data = imputed_data2, 
                       true_labels = component, 
                       predicted_labels = predicted_labels2, 
                       normalization = "missing", 
                       alpha = 0.5, 
                       beta = 0.5)

metrics_summary <- data.frame(
  Method = c("Model wo C", "Model w C"),
  NRMSE = c(round(nrmse1, 4), round(nrmse2, 4)),
  WNRMSE = c(round(wnrmse1, 4), round(wnrmse2, 4)),
  ARI = c(round(similarity_metrics1$ARI, 4), round(similarity_metrics2$ARI, 4)),
  CIIE = c(round(ciie1, 4), round(ciie2, 4))
)

print(metrics_summary)

```

```{r}
x <- data_missing
x <- as.matrix(x)
n <- as.integer(nrow(x))
p <- as.integer(ncol(x))
n_iter <- 50

C_orig <- matrix(as.numeric(is.na(x)), nrow = n, ncol = p)
# tau_old <- result_wo_C$proba
tau <- result_wo_C$proba
S <- result_wo_C$S
number_clusters <- result_wo_C$nbcluster
m <- length(S)
# For each cluster k and each variable in S, fit an intercept-only GLM (probit link)
alpha_hat <- matrix(NA, nrow = number_clusters, ncol = length(S))
      for (k in 1:number_clusters) {
        for (s in seq_along(S)) {
          j <- S[s]
          fit <- glm(C_orig[, j] ~ 1, weights = tau_old[, k], family = binomial(link = "probit"))
          alpha_hat[k, s] <- coef(fit)[1]
        }
      }
# Compute likelihood contribution L_mat for each observation i and cluster k
L_mat <- matrix(NA, nrow = n, ncol = number_clusters)
      for (i in 1:n) {
        for (k in 1:number_clusters) {
          L_val <- 1
          for (s in seq_along(S)) {
            j <- S[s]
            prob <- pnorm(alpha_hat[k, s])
            if (is.na(x[i, j])) {
              L_val <- L_val * prob
            } else {
              L_val <- L_val * (1 - prob)
            }
          }
          L_mat[i, k] <- L_val
        }
      }

# Update responsibilities
# tau_new <- tau_old * L_mat
# tau_new <- tau_new / rowSums(tau_new)
# result_wo_C$proba_corrected <- tau_new
# Update imputed values
# Use conditional expectation
x_corrected <- result_wo_C$imputedData

for (iter in 1:n_iter) {
  if (iter %% 10 == 0){
  cat("Hybrid correction iteration", iter, "\n")}
  # E-step: Estimate mechanism parameters for each cluster and variable in S.
  for (k in 1:number_clusters) {
    for (s in 1:m) {
      j <- S[s]
      fit <- suppressWarnings(glm(C_orig[, j] ~ 1, weights = tau[, k],
                                  family = binomial(link = "probit")))
      alpha_hat[k, s] <- coef(fit)[1]
    }
  }
  
  # Compute likelihood contributions L_mat for each observation and cluste
  for (i in 1:n) {
    for (k in 1:number_clusters) {
      L_val <- 1
      for (s in 1:m) {
        j <- S[s]
        prob <- pnorm(alpha_hat[k, s])
        # If x[i, j] is missing, use prob; else use 1-prob.
        if (is.na(x[i, j])) {
          L_val <- L_val * prob
        } else {
          L_val <- L_val * (1 - prob)
        }
      }
      L_mat[i, k] <- L_val
    }
  }
  
  # Update responsibilities
  tau_new <- tau * L_mat
  tau_new <- tau_new / rowSums(tau_new)
  
  # M-step: Update imputed values for missing entries.
  for (i in 1:n) {
    missing_idx <- which(is.na(x[i, S]))
    if (length(missing_idx) > 0) {
      for (s in missing_idx) {
        impute_val <- 0
        for (k in 1:number_clusters) {
          # In your model, finalModel$parameters@mean is a matrix (number_clusters x m)
          mu_k <- result_w_C$parameters@mean[k, ]
          # For diagonal covariance, the conditional expectation is simply mu_k[s]
          cond_exp <- mu_k[s]
          impute_val <- impute_val + tau_new[i, k] * cond_exp
        }
        # Update the imputed value at the original column index S[s]
        x_corrected[i, S[s]] <- impute_val
      }
    }
  }
  
  # Update tau
  tau <- tau_new
}

result_w_C$proba_corrected <- tau
result_w_C$imputedData <- x_corrected


```


# Asymptotic Chi-squared
Some key notes:

+ The empirical LRT statistics have heavier tails than expected under $\chi^2_{2}$

+ Extreme deviations occur in the upper tail, suggesting non-standard asymptotics 

```{r}
set.seed(123)
n <- 2000  
K <- 2     

p <- c(0.5, 0.5)

# Clustering (S) parameters: 3 variables
mu1 <- c(0, 0, 0)
mu2 <- c(3, -3, 1)
mu_list <- list(mu1, mu2)
Sigma1 <- diag(1, 3)
Sigma2 <- diag(1, 3)
Sigma_list <- list(Sigma1, Sigma2)

# Regression (S^c) parameters: 2 variables
a <- c(1, -1)            # intercept (length 2)
Omega <- diag(c(1,1))    # error covariance (2x2)

# Full model regression parameters R0 = {V1, V2}
beta_full <- matrix(c(0.5, 1,
                      0.2, -0.3), nrow = 2, byrow = TRUE)  # 2x2 matrix
# Embed beta_full into a 3x2 matrix (nonzero rows for predictors V1,V2; zero for V3)
tilde_beta_full <- rbind(beta_full, c(0, 0))   # dimension 3 x 2

# Reduced model: restrict the effect of V2 to zero
beta_reduced <- matrix(c(0.5, 1), nrow = 1)  # 1 x 2 matrix
tilde_beta_reduced <- rbind(beta_reduced, matrix(0, nrow = 2, ncol = 2))  # 3 x 2

# Simulate complete data from the full model
# first 3 entries (S: V1-V3) and last 2 entries (S^c: V4-V5).

data_mat <- matrix(NA, nrow = n, ncol = 5)
true_component <- numeric(n)

for(i in 1:n){
  k <- sample(1:K, 1, prob = p)
  true_component[i] <- k
  
  y_S <- mvrnorm(1, mu = mu_list[[k]], Sigma = Sigma_list[[k]])
  
  mean_reg <- as.vector(a + t(tilde_beta_full) %*% mu_list[[k]])
  cov_reg <- Omega + t(tilde_beta_full) %*% Sigma_list[[k]] %*% tilde_beta_full
  
  y_reg <- mvrnorm(1, mu = mean_reg, Sigma = cov_reg)
  
  data_mat[i, ] <- c(y_S, y_reg)
}
colnames(data_mat) <- c("V1", "V2", "V3", "V4", "V5")

# Compute the observed loglikelihood
# For each observation, the likelihood is computed as a mixture:
#   f(y_i^o) = sum_{k=1}^K pk * dmvnorm( y_S | muk, Sigmak ) *
#                         dmvnorm( y_{S^c} | a + t(tilde_beta)*muk, Omega + t(tilde_beta)*Sigmak*tilde_beta)
logLik_obs <- function(data, p, mu_list, Sigma_list, a, Omega, tilde_beta) {
  n <- nrow(data)
  loglik <- numeric(n)
  
  for(i in 1:n){
    y_S   <- data[i, 1:3]  
    y_reg <- data[i, 4:5]
    
    comp_density <- numeric(length(p))
    for(k in 1:length(p)){
      dens_S <- dmvnorm(y_S, mean = mu_list[[k]], sigma = Sigma_list[[k]])
      
      mean_reg <- as.vector(a + t(tilde_beta) %*% mu_list[[k]])
      cov_reg <- Omega + t(tilde_beta) %*% Sigma_list[[k]] %*% tilde_beta
      
      dens_reg <- dmvnorm(y_reg, mean = mean_reg, sigma = cov_reg)
      
      comp_density[k] <- p[k] * dens_S * dens_reg
    }
    # Avoid log(0)
    loglik[i] <- log(sum(comp_density) + 1e-12)
  }
  return(sum(loglik))
}

# Observed loglikelihood under the two models
logL_full    <- logLik_obs(data_mat, p, mu_list, Sigma_list, a, Omega, tilde_beta_full)
logL_reduced <- logLik_obs(data_mat, p, mu_list, Sigma_list, a, Omega, tilde_beta_reduced)

LR_obs <- 2 * (logL_full - logL_reduced)
cat("Observed LR statistic =", LR_obs, "\n")

# Bootstrap the LR statistic under the null (reduced model)
# We simulate new datasets from the reduced model (tilde_beta_reduced)
# and then compute the LR statistic (comparing the full and reduced likelihoods) on each dataset.
Bsim <- 200
LR_boot <- numeric(Bsim)
set.seed(456)
for(b in 1:Bsim){
  data_boot <- matrix(NA, nrow = n, ncol = 5)
  for(i in 1:n){
    k <- sample(1:K, 1, prob = p)
    
    # Clustering part remains the same:
    y_S <- mvrnorm(1, mu = mu_list[[k]], Sigma = Sigma_list[[k]])
    
    # Regression part under the reduced model:
    mean_reg <- as.vector(a + t(tilde_beta_reduced) %*% mu_list[[k]])
    cov_reg <- Omega + t(tilde_beta_reduced) %*% Sigma_list[[k]] %*% tilde_beta_reduced
    y_reg <- mvrnorm(1, mu = mean_reg, Sigma = cov_reg)
    
    data_boot[i, ] <- c(y_S, y_reg)
  }
  
  ll_full_boot    <- logLik_obs(data_boot, p, mu_list, Sigma_list, a, Omega, tilde_beta_full)
  ll_reduced_boot <- logLik_obs(data_boot, p, mu_list, Sigma_list, a, Omega, tilde_beta_reduced)
  
  LR_boot[b] <- 2 * (ll_full_boot - ll_reduced_boot)
}

# Compare the empirical distribution with the theoretical one
# Under the null, the number of restrictions is the difference in the number of free parameters in .
# Here, full model: _full is 22 (4 parameters), reduced model: only 12 (2 parameters).
# So the degrees of freedom is 2.
x_grid <- seq(0, max(c(LR_boot[LR_boot!=0], LR_obs, 10)), length.out = 500)
ecdf_LR <- ecdf(LR_boot[LR_boot!=0])
cdf_chisq <- pchisq(x_grid, df = 2)

# Plot the empirical CDF and the chi-square CDF.
plot(x_grid, ecdf_LR(x_grid), type = "l", lwd = 2, col = "blue",
     xlab = "LR Statistic", ylab = "CDF", main = "ECDF of LR Statistic vs. Chi-square CDF")
lines(x_grid, cdf_chisq, col = "red", lwd = 2, lty = 2)
abline(v = LR_obs, col = "darkgreen", lwd = 2)
legend("bottomright", legend = c("Empirical CDF", "Chi-square CDF (df=2)", 
                                  paste("Observed LR =", round(LR_obs,2))),
       col = c("blue", "red", "darkgreen"), lwd = 2, lty = c(1,2,1))

cat("Mean simulated LR =", mean(LR_boot), "\n")
cat("SD of simulated LR =", sd(LR_boot), "\n")



ks.test(LR_boot[LR_boot!=0], "pchisq", 2)
```
